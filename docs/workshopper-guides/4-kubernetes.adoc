== First step with Kubernetes

Following a microservice approach will help you increase your _agility_. However, it does not come for free and
requires a lot of discipline. It also stresses your deployment facilities. When the number of microservices grows, it
very quickly becomes an issue to keep your system on track.

To help us with this, containers are a great packaging and runtime technology. Your application runs in an
_isolated_ container, avoiding resource conflicts. But to deploy a set of containers and keep them coordinated, you
need a container platform. That's what Kubernetes is. Kubernetes defines a set of building blocks ("primitives") which
collectively provide mechanisms for deploying, maintaining, and scaling applications packaged inside containers. OpenShift
 _extends_ Kubernetes with build automation and a routing system, while inheriting all the primitives from Kubernetes.

image::openshift-architecture.png[OpenShift Architecture, 800]

=== Primitives

==== Pod

The basic scheduling unit in Kubernetes is called a _pod_. It adds a higher level of abstraction to containerized components.
A pod consists of one or more containers that are guaranteed to be co-located on the host machine and can share resources.
Each pod in Kubernetes is assigned a unique (within the cluster) IP address, which allows applications to use ports without
 the risk of conflict. A pod can define a _volume_, such as a local disk directory or a network disk, and expose it to
 the containers in the pod. Pods can be manually managed through the Kubernetes API, or their management can be
 delegated to a controller.

==== Labels and Selectors

Kubernetes enables clients (users or internal components) to attach key-value pairs called _labels_ to any API object
 in the system, such as pods. Correspondingly, _label selectors_ are queries against labels that resolve to matching
 objects. Labels and selectors are the primary grouping mechanism in Kubernetes and are used to determine the components
 to which an operation applies. Labels and selectors are used to group entities together.

==== Replication Controller and Deployment

Controllers are entities managing other entities in order to keep them in a specific state. For instance, a
replication controller has the responsibility to keep alive _x_ replicas of a pod. When one of these replicas dies or
 becomes unresponsive, the controller kills it and restarts one. Likewise, if there are more replicas running than desired,
  it deletes as many as necessary to match the number.

The definition of a replication controller consists mainly of:

1. The number of replicas desired (which can be adjusted at runtime).
2. A pod definition for creating a replicated pod.
3. A selector for identifying managed pods (using labels)

Building on replication controllers, OpenShift expands support for the deployment lifecycle with the concept of _deployments_.
 In the simplest case, a deployment just creates a new replication controller and lets it start up pods. However, OpenShift
  deployments also provide the ability to transition from an existing deployment (_v1_ for instance) of an image to a new
  one (_v2_ for instance) and also define hooks to be run before or after creating the replication controller.

Openshift deployments propose a set of strategies. The default is _rolling_ which implements (as the name implies) rolling 
updates and ensures that you don't disrupt your service. Before stopping the pod, it ensures that the new _version_ is alive and 
ready. Then, it routes requests to this new pod and dispose the old one.  Other strategies provided include _recreate_, 
_blue-green_, _A/B_, and the ability to create a custom strategy.

==== Build and Image

As stated in the previous section, `deployments` are responsible for keeping the application running. But we need to
provide the application first. The application is pushed to OpenShift as an (container) _image_. This image is
created by a _build_ and instantiated by the _deployment_.

A build is the process of transforming your code into an image. The process is described in a `BuildConfig` object. Build
objects share common characteristics: inputs for a build (source code, artifacts), the need to complete a build process,
logging the build process, publishing resources from successful builds, and publishing the final status of the build.

There are different types of builds. You can create a `Docker` build taking a `Dockerfile` as parameter. The
resulting image is generated by _building_ the `Dockerfile`. OpenShift also provides the concept of S2I (Source to
Image) as a tool to provide reproducible images. In this lab, we are going to use S2I with binary content. We are
going to build the application on our machine and push the resulting artifact (a _fat jar_) as input to an S2I build.
This build creates an image for starting the application.

image::openshift-build-process.png[OpenShift Build Process, 800]

==== Services

Ok, so we know how our application is going to be _built_ and instantiated on OpenShift. But how are we going to use
it? For this we need _services_. A _service_ identifies a set of pods (using labels) in order to proxy the connections
it receives to them. Backing pods can be added to or removed from a service arbitrarily while the service remains
consistently available enabling anything that depends on the service to refer to it at a consistent internal address.

Services are assigned an IP address and port pair that, when accessed, proxy to an appropriate backing pod. A service
uses a label selector to find all the containers running that provide a certain network service on a certain port.

image::openshift-service.png[OpenShift Services, 400]

==== Routes

_Routes_ are the last concept to understand before starting to use OpenShift. Services provides an internal IP.
Routes exposes a service outside of OpenShift. A route allows you to associate a service with an externally-reachable
 host name.

image::openshift-entities.png[OpenShift Entities, 800]

=== Installing and Starting OpenShift

We are going to use _minishift_ (https://github.com/minishift/minishift) to run OpenShift locally on your machine.

Before starting minishift, you need to install a hypervisor. Check the https://docs.openshift.org/latest/minishift/getting-started/installing.html 
to check what are the supported ones for your operating system. When in doubt, use VirtualBox (https://www.virtualbox.org/wiki/Downloads). 
Be sure to have a hypervisor before continuing.

If not already done, download the latest release from https://github.com/minishift/minishift/releases (do not
use beta). Download the archive and copy the `minishift` executable in the directory of your choice. Add this
directory to your system `$PATH`. 

Then, in a terminal, run:

[source, bash]
----
minishift start
----

When the starting sequence completes, you should get the URL of the OpenShift Web Console such as: `https://192.168
.64.12:8443`. Open this url in a browser and connect using the default `developer/developer` credentials.

Now we have OpenShift running, but we need a way to interact with it. The _OpenShift Client_ (`oc`) is a command line
 tool to interact with OpenShift. Fortunately, this client is shipped with minishift. Use `minishift oc-env` to display
  the command you need to type into your shell in order to add the oc binary to your PATH environment variable. Then,
   run the following `oc` command to connect to your OpenShift instance:

[source, bash]
----
oc login -u developer -p developer
----

TIP: for Unix style shells you can run `eval $(minishift oc-env)` to make `oc` available.

Now, you are ready to deploy your first application.

=== Your first project and deployment

We are going to use a specific project to host all the microservices developed in this lab. A `project` is a
namespace making easy to organize your different applications in OpenShift. In a terminal run:

[source, bash]
----
oc new-project vertx-kubernetes-workshop
oc policy add-role-to-user view admin -n vertx-kubernetes-workshop
oc policy add-role-to-user view -n vertx-kubernetes-workshop -z default
oc policy add-role-to-group view system:serviceaccounts -n vertx-kubernetes-workshop
----

The first instruction creates the project. The 3 last instructions grant permissions in order to use all the
OpenShift capabilities.

In the OpenShift Web Console, you should see the newly created project. Click on it. It's empty, so let's deploy our
first application.

In the workshop source code, locate the `currency-3rdparty-service` and navigate to the directory in your terminal.
Now issue the `mvn fabric8:deploy` command:

[source, bash]
----
cd $WORKSHOP_ROOT/currency-3rdparty-service
mvn fabric8:deploy
----

The `fabric8 maven plugin` is a Maven Plugin facilitating the deployment of OpenShift applications. The `:deploy`
mojo packages the application and triggers the S2I build described above.

In your browser, check the content of the project. You should see something like:

image::openshift-first-deployment.png[First deployment, 1024]


Click on the route url and you should see `ok`.  This indicates that your first application was successfully deployed.


